import{_ as o,o as n,c as a,a as e}from"./index-5ac8332a.js";const t={},s=e("h1",{id:"llama-terminal-completion"},"Llama Terminal Completion",-1),r=e("p",null,"Ever wish you could look up Linux commands or ask questions and receive responses from the terminal? You probably need a paid service, an API key with paid usage, or at least an internet connection, right? Not with Llama Terminal Completion. Instead, we'll Run a Large Language Model (think ChatGPT) locally, on your personal machine, and generate responses from there.",-1),i=[s,r];function l(c,_){return n(),a("div",null,i)}const m=o(t,[["render",l]]);export{m as default};
